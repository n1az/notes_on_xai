Cluster-based visualization techniques in explainable AI (xAI) focus on grouping similar explanations to better understand the model's behavior.

1. **SHAP Clustering**: This method uses SHAP values to explain model predictions and clusters these values to identify patterns and outliers[https://arxiv.org/pdf/2402.04982.pdf]. Explainable artificial intelligence: a comprehensive review[https://link.springer.com/article/10.1007/s10462-021-10088-y].

2. **t-SNE and UMAP for High-Dimensional Data**: These dimensionality reduction techniques are used to visualize high-dimensional data like SHAP values or feature importance vectors, effectively clustering similar explanations[https://pair-code.github.io/understanding-umap/]. Towards a comprehensive evaluation of dimension reduction methods for transcriptomic data visualization[https://www.nature.com/articles/s42003-022-03628-x]Explainable AI: current status and future directions[https://arxiv.org/abs/2107.07045].

3. **Hierarchical Clustering of Feature Importance**: Applying hierarchical clustering to feature importance vectors can create a dendrogram that groups similar instances, providing insights into model decisions[https://arxiv.org/pdf/2112.01372.pdf].

4. **Activation Atlases**: By aggregating activations across many datapoints, this technique creates a high-level overview of the types of features a neural network is detecting. [https://distill.pub/2019/activation-atlas/].

5. **Projection-Based Clustering**: Methods like PCA are used to project feature importance vectors onto lower dimensions, followed by clustering to group similar explanations. [https://www.researchgate.net/publication/378158153_An_Object-Based_Approach_to_Differentiate_Pores_and_Microfractures_in_Petrographic_Analysis_Using_Explainable_Supervised_Machine_Learning]. Identification of Explainable Structures in Data with a Human-in-the-Loop[https://link.springer.com/article/10.1007/s13218-022-00782-6].

6. A Deep Diagnostic Framework Using Explainable Artificial Intelligence and Clustering[https://www.mdpi.com/2075-4418/13/22/3413].

7. A survey of visual analytics for Explainable Artificial Intelligence methods[https://www.sciencedirect.com/science/article/pii/S0097849321001886].

8. TimeCluster: dimension reduction applied to temporal data for visual analytics[https://link.springer.com/content/pdf/10.1007/s00371-019-01673-y.pdf].

9. Clustervision: Visual Supervision of Unsupervised Clustering[https://ieeexplore.ieee.org/document/8019866].

10. Spectral relevance analysis (SpRAy) | Unmasking Clever Hans predictors and assessing what machines really learn[https://www.nature.com/articles/s41467-019-08987-4#Sec6].

11. Neuralization-propagation | From Clustering to Cluster Explanations via Neural Networks[https://arxiv.org/pdf/1906.07633.pdf].

12. Towards explaining anomalies: A deep Taylor decomposition of one-class models[https://www.sciencedirect.com/science/article/pii/S0031320320300054].

13. NEON | Explaining the Predictions of Unsupervised Learning Models[https://link.springer.com/chapter/10.1007/978-3-031-04083-2_7].

14. Deep Learning Using Explainable Artificial Intelligence and Clustering[https://encyclopedia.pub/entry/51965].
